{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "\n",
    "def is_user_alive(user_data):\n",
    "    train = pd.read_csv(os.path.join('input', 'train.csv'))\n",
    "    test = pd.read_csv(os.path.join('input', 'test.csv'))\n",
    "\n",
    "\n",
    "\n",
    "    user_data = [0,3,'Davies, Mr. John Samuel','male',21,2,0,48871,24.15, ',','S']\n",
    "\n",
    "    with open(os.path.join('input', 'test.csv'), \"a\") as fp:\n",
    "        wr = csv.writer(fp, dialect='excel')\n",
    "        wr.writerow(user_data)\n",
    "\n",
    "\n",
    "\n",
    "    train['Survived'].value_counts(normalize=True)\n",
    "\n",
    "    sns.countplot(train['Survived'])\n",
    "\n",
    "    train['Survived'].groupby(train['Pclass']).mean()\n",
    "\n",
    "    sns.countplot(train['Pclass'], hue=train['Survived'])\n",
    "\n",
    "    train['Name_Title'] = train['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "    train['Name_Title'].value_counts()\n",
    "\n",
    "    train['Survived'].groupby(train['Name_Title']).mean()\n",
    "\n",
    "    train['Name_Len'] = train['Name'].apply(lambda x: len(x))\n",
    "    train['Survived'].groupby(pd.qcut(train['Name_Len'],5)).mean()\n",
    "\n",
    "    pd.qcut(train['Name_Len'],5).value_counts()\n",
    "\n",
    "    train['Sex'].value_counts(normalize=True)\n",
    "\n",
    "    train['Survived'].groupby(train['Sex']).mean()\n",
    "\n",
    "    train['Survived'].groupby(train['Age'].isnull()).mean()\n",
    "\n",
    "    train['Survived'].groupby(pd.qcut(train['Age'],5)).mean()\n",
    "\n",
    "    pd.qcut(train['Age'],5).value_counts()\n",
    "\n",
    "    train['Survived'].groupby(train['SibSp']).mean()\n",
    "\n",
    "    train['SibSp'].value_counts()\n",
    "\n",
    "    train['Survived'].groupby(train['Parch']).mean()\n",
    "\n",
    "    train['Parch'].value_counts()\n",
    "\n",
    "    train['Ticket'].head(n=10)\n",
    "\n",
    "    train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "\n",
    "    train['Ticket_Len'].value_counts()\n",
    "\n",
    "    train['Ticket_Lett'] = train['Ticket'].apply(lambda x: str(x)[0])\n",
    "\n",
    "    train['Ticket_Lett'].value_counts()\n",
    "\n",
    "    train.groupby(['Ticket_Lett'])['Survived'].mean()\n",
    "\n",
    "    pd.qcut(train['Fare'], 3).value_counts()\n",
    "\n",
    "    train['Survived'].groupby(pd.qcut(train['Fare'], 3)).mean()\n",
    "\n",
    "    pd.crosstab(pd.qcut(train['Fare'], 5), columns=train['Pclass'])\n",
    "\n",
    "    train['Cabin_Letter'] = train['Cabin'].apply(lambda x: str(x)[0])\n",
    "\n",
    "    train['Cabin_Letter'].value_counts()\n",
    "\n",
    "    train['Survived'].groupby(train['Cabin_Letter']).mean()\n",
    "\n",
    "    train['Cabin_num'] = train['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    train['Cabin_num'].replace('an', np.NaN, inplace = True)\n",
    "    train['Cabin_num'] = train['Cabin_num'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "\n",
    "    pd.qcut(train['Cabin_num'],3).value_counts()\n",
    "\n",
    "    train['Survived'].groupby(pd.qcut(train['Cabin_num'], 3)).mean()\n",
    "\n",
    "    train['Survived'].corr(train['Cabin_num'])\n",
    "\n",
    "    train['Embarked'].value_counts()\n",
    "\n",
    "    train['Embarked'].value_counts(normalize=True)\n",
    "\n",
    "    train['Survived'].groupby(train['Embarked']).mean()\n",
    "\n",
    "    sns.countplot(train['Embarked'], hue=train['Pclass'])\n",
    "\n",
    "    def names(train, test):\n",
    "        for i in [train, test]:\n",
    "            i['Name_Len'] = i['Name'].apply(lambda x: len(x))\n",
    "            i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "            del i['Name']\n",
    "        return train, test\n",
    "\n",
    "    def age_impute(train, test):\n",
    "        for i in [train, test]:\n",
    "            i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "            data = train.groupby(['Name_Title', 'Pclass'])['Age']\n",
    "            i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "        return train, test\n",
    "\n",
    "    def fam_size(train, test):\n",
    "        for i in [train, test]:\n",
    "            i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n",
    "                               np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n",
    "            del i['SibSp']\n",
    "            del i['Parch']\n",
    "        return train, test\n",
    "\n",
    "    def ticket_grouped(train, test):\n",
    "        for i in [train, test]:\n",
    "            i['Ticket_Lett'] = i['Ticket'].apply(lambda x: str(x)[0])\n",
    "            i['Ticket_Lett'] = i['Ticket_Lett'].apply(lambda x: str(x))\n",
    "            i['Ticket_Lett'] = np.where((i['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['Ticket_Lett'],\n",
    "                                       np.where((i['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                                'Low_ticket', 'Other_ticket'))\n",
    "            i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))\n",
    "            del i['Ticket']\n",
    "        return train, test\n",
    "\n",
    "    def cabin(train, test):\n",
    "        for i in [train, test]:\n",
    "            i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])\n",
    "            del i['Cabin']\n",
    "        return train, test\n",
    "\n",
    "    def cabin_num(train, test):\n",
    "        for i in [train, test]:\n",
    "            i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "            i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "            i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "            i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n",
    "        train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "        del train['Cabin_num']\n",
    "        del test['Cabin_num']\n",
    "        del train['Cabin_num1']\n",
    "        del test['Cabin_num1']\n",
    "        return train, test\n",
    "\n",
    "    def embarked_impute(train, test):\n",
    "        for i in [train, test]:\n",
    "            i['Embarked'] = i['Embarked'].fillna('S')\n",
    "        return train, test\n",
    "\n",
    "    test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "\n",
    "    def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):\n",
    "        for column in columns:\n",
    "            train[column] = train[column].apply(lambda x: str(x))\n",
    "            test[column] = test[column].apply(lambda x: str(x))\n",
    "            good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "            train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "            test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "            del train[column]\n",
    "            del test[column]\n",
    "        return train, test\n",
    "\n",
    "    def drop(train, test, bye = ['PassengerId']):\n",
    "        for i in [train, test]:\n",
    "            for z in bye:\n",
    "                del i[z]\n",
    "        return train, test\n",
    "\n",
    "    train = pd.read_csv(os.path.join('input', 'train.csv'))\n",
    "    test = pd.read_csv(os.path.join('input', 'test.csv'))\n",
    "    train, test = names(train, test)\n",
    "    train, test = age_impute(train, test)\n",
    "    train, test = cabin_num(train, test)\n",
    "    train, test = cabin(train, test)\n",
    "    train, test = embarked_impute(train, test)\n",
    "    train, test = fam_size(train, test)\n",
    "    test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "    train, test = ticket_grouped(train, test)\n",
    "    train, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett',\n",
    "                                                                         'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "    train, test = drop(train, test)\n",
    "\n",
    "    print(len(train.columns))\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    rf = RandomForestClassifier(criterion='gini',\n",
    "                                 n_estimators=700,\n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 max_features='auto',\n",
    "                                 oob_score=True,\n",
    "                                 random_state=1,\n",
    "                                 n_jobs=-1)\n",
    "    rf.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "    print(\"%.4f\" % rf.oob_score_)\n",
    "\n",
    "    pd.concat((pd.DataFrame(train.iloc[:, 1:].columns, columns = ['variable']),\n",
    "               pd.DataFrame(rf.feature_importances_, columns = ['importance'])),\n",
    "              axis = 1).sort_values(by='importance', ascending = False)[:20]\n",
    "\n",
    "    predictions = rf.predict(test)\n",
    "    predictions = pd.DataFrame(predictions, columns=['Survived'])\n",
    "    test = pd.read_csv(os.path.join('input', 'test.csv'))\n",
    "    predictions = pd.concat((test.iloc[:, 0], predictions), axis = 1)\n",
    "    predictions.to_csv('y_test15.csv', sep=\",\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "    return predictions[len(predictions)-1:]['Survived']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}